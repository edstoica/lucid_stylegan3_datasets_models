{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "StyleGAN3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/edstoica/lucid_stylegan3_datasets_models/blob/main/StyleGAN3-Toolkit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHzltei9Ue7I"
      },
      "source": [
        "#StyleGAN3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVF2P1OlT92b"
      },
      "source": [
        "#Lucid Stylegan3 models evaluation\n",
        "\n",
        "This basic colab notebook is to try out the **[lucid stylegan3 datasets and models](https://github.com/edstoica/lucid_stylegan3_datasets_models)** collection.\n",
        "\n",
        "This notebook is derived from [here](https://colab.research.google.com/drive/1BXNHZBai-pXtP-ncliouXo_kUiG1Pq7M?usp=sharing#scrollTo=WVF2P1OlT92b). \n",
        "\n",
        "<!--\n",
        "**[UPD 18.10.2021]** Added ThisSneakersDoesn'tExist model by [@stan_vossen](https://twitter.com/stan_vossen)  +  seems like [@l4rz](https://twitter.com/l4rz) killed the model for cosplay\n",
        "\n",
        "[UPD 17.10.2021] Added Music Video Generation (originally inspired by [this tweet](https://twitter.com/hexorcismos/status/1449032666574213125?s=20))\n",
        "\n",
        "[UPD 14.10.2021] Added Cosplay Faces trained by [@l4rz](https://twitter.com/l4rz)-->"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d99HsTjTQRzg",
        "cellView": "form"
      },
      "source": [
        "#@title Install System\n",
        "#@markdown play only once (ignore that memory warning)\n",
        "from IPython.display import clear_output\n",
        "\n",
        "!git clone https://github.com/NVlabs/stylegan3.git\n",
        "%cd stylegan3\n",
        "!wget -O mini.sh https://repo.anaconda.com/miniconda/Miniconda3-py38_4.8.2-Linux-x86_64.sh\n",
        "!chmod +x mini.sh\n",
        "!bash ./mini.sh -b -f -p /usr/local\n",
        "!conda install -q -y --prefix /usr/local jupyter\n",
        "!python -m ipykernel install --name \"py38\" --user\n",
        "!pip install click -q\n",
        "!pip install numpy -q\n",
        "!pip install pillow -q\n",
        "!pip install torch -q\n",
        "!pip install scipy -q\n",
        "!pip install Ninja -q\n",
        "!pip install imageio -q\n",
        "!pip install imageio-ffmpeg -q\n",
        "!pip install youtube-dl -q\n",
        "clear_output()\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Select model \n",
        "#@markdown (replay this when you change selection)\n",
        "modellink = 'test'\n",
        "model = \"scifi city - 256 - step 210\" #@param [\"mechanical devices from the future - 256 - step 29\", \"flowers - 256 - step 69\", \"alien sunglases - 256 - step 38\", \"forest daemons - 256 - step 18\", \"scifi city - 256 - step 210\", \"scifi spaceship - 256 - step 162\", \"yellow alien - 512 - step 236\"]\n",
        "if model == 'mechanical devices from the future - 256 - step 29':\n",
        "   modellink = 'https://www.dropbox.com/s/v2oie53cz62ozvu/network-snapshot-000029.pkl?dl=1'\n",
        "if model == 'flowers - 256 - step 69':\n",
        "   modellink = 'https://www.dropbox.com/s/o33lhgnk91hstvx/network-snapshot-000069.pkl?dl=1'\n",
        "if model == 'alien sunglases - 256 - step 38':\n",
        "   modellink = 'https://www.dropbox.com/s/vhwghutjz6xccf9/network-snapshot-000074.pkl?dl=1'\n",
        "if model == 'forest daemons - 256 - step 18':\n",
        "   modellink = 'https://www.dropbox.com/s/26muctr2eq4br6l/network-snapshot-000018.pkl?dl=1'\n",
        "if model == 'scifi city - 256 - step 210':\n",
        "   modellink = 'https://www.dropbox.com/s/1kfsmlct4mriphc/network-snapshot-000210.pkl?dl=1'\n",
        "if model == 'scifi spaceship - 256 - step 162':\n",
        "   modellink = 'https://www.dropbox.com/s/02br3mjkma1hubc/network-snapshot-000162.pkl?dl=1'\n",
        "if model == 'yellow alien - 512 - step 236':\n",
        "   modellink = 'https://www.dropbox.com/s/yzraojzmg2kybjx/network-snapshot-000236.pkl?dl=1'"
      ],
      "metadata": {
        "cellView": "form",
        "id": "LNieeZHBub3O"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkBzNIQ9QsFB",
        "cellView": "form"
      },
      "source": [
        "#@title Generate an image\n",
        "\n",
        "seed = 1053 #@param {type:\"slider\", min:0, max:9999, step:1}\n",
        "\n",
        "# Generate an image using pre-trained model \n",
        "!python gen_images.py --outdir=out --trunc=1 \\\n",
        " --seeds=$seed --network=$modellink\n",
        " \n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "img = Image.open('/content/stylegan3/out/seed%04d.png' % seed);\n",
        "plt.imshow(img);\n",
        "plt.axis('off');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "8JGiupAAvdqF"
      },
      "source": [
        "#@title Generate an interpolation video\n",
        "%cd /content/stylegan3\n",
        "\n",
        "#@markdown Select Seeds (keyframes):\n",
        "start_seed = 42 #@param {type:\"number\"}\n",
        "stop_seed = 46 #@param {type:\"number\"}\n",
        "#@markdown you like to generate a video grid?\n",
        "n_cols =  1#@param {type:\"number\"}\n",
        "n_rows = 1 #@param {type:\"number\"}\n",
        "\n",
        "# #@markdown How many key frames to have?\n",
        "# num_keyframes = 3 #@param {type:\"number\"}\n",
        "num_keyframes = 3\n",
        "\n",
        "#@markdown How many frames for interpolation between each seed?\n",
        "w_frames = 100 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown Total length in frames is `num_keyframes`*`w_frames`\n",
        "\n",
        "assert stop_seed > start_seed, 'Stop_seed should be larger then start_seed'\n",
        "\n",
        "if model == \"stylegan2-cosplay-faces-512x512-px\":\n",
        "    baselink = 'https://l4rz.net/'\n",
        "    model = 'cosplayface-snapshot-004000-18160-FID367.pkl'\n",
        "\n",
        "if model == 'sneakers':\n",
        "    if 'sneaksnap.pkl' not in os.listdir('/content/stylegan3'):\n",
        "        !gdown --id 1ReK9P4dkkClvpswdSuew35xCx2xjVsQa\n",
        "    baselink = '/content/stylegan3/'\n",
        "    model = 'sneaksnap.pkl'\n",
        "\n",
        "# Render a  grid of interpolations for seeds N through K.\n",
        "!python gen_video.py --output=lerp.mp4 --trunc=1 --seeds=$start_seed-$stop_seed --grid={n_rows}x{n_cols} \\\n",
        "    --network=$modellink \\\n",
        "    --w-frames=$w_frames\n",
        "\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "mp4 = open('lerp.mp4','rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "<i>right click and \"save video\" for download</i>\n",
        "\"\"\" % data_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Vsm7h-yi25b",
        "cellView": "form"
      },
      "source": [
        "# @title \n",
        "# # work in progress\n",
        "# # make visualizer\n",
        "# # stop looping, start parallelizing\n",
        "# # Clone Real-ESRGAN and enter the Real-ESRGAN\n",
        "# !git clone https://github.com/xinntao/Real-ESRGAN.git\n",
        "# %cd Real-ESRGAN\n",
        "# # Set up the environment\n",
        "# !pip install --upgrade basicsr\n",
        "# # !pip install facexlib\n",
        "# # !pip install gfpgan\n",
        "# # !pip install -r requirements.txt\n",
        "# # !python setup.py develop\n",
        "# # # Download the pre-trained model\n",
        "# # !wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth -P experiments/pretrained_models"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}